\documentclass[aspectratio=169, 10pt]{beamer}

\usepackage{booktabs, libertinus, subfiles, tikz, colortbl, multirow, natbib, varwidth}
\usetikzlibrary{positioning, matrix, fit, decorations, shapes, shapes.misc, decorations.pathreplacing, calc, backgrounds}
\input{figureconf}
\input{figures/derivs/00-survey-lexderiv-commands.tex}

\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}{%
    \null\hspace*{2pt}%
    \insertsection%
    \hspace*{\fill}%
    \usebeamercolor[fg]{frame number in head/foot}%
    \usebeamerfont{frame number in head/foot}%
    \insertframenumber\,/\,\inserttotalframenumber%
    \hspace*{2pt}\vskip2pt%
}
\setbeamertemplate{itemize item}{--}
\setbeamertemplate{itemize subitem}{--}

\title{On the Extraction of Lexicalized Grammars\\and Parsing via Supertagging\\for Discontinuous Constituent Structures}
\subtitle{Phd defense}
\newcommand{\theemails}{%
    \href{thomas.ruprecht@tu-dresden.de}{thomas.ruprecht@tu-dresden.de}%
}
\author{\texorpdfstring{Thomas Ruprecht\\{\small \theemails}}{Thomas Ruprecht}}
\institute{Institute for Theoretical Computer Science\\Faculty of Computer Science\\Technische Universität Dresden, Germany}
\date{June 5, 2024}

%\includeonlyframes{working}
\begin{document}
    \begin{frame}[noframenumbering,plain]
        \maketitle
    \end{frame}

    \begin{frame}{Outline}
        \tableofcontents
    \end{frame}

    \section{Introduction}
    \subfileinclude{introduction.tex}
    \subfileinclude{hybrid-grammars.tex}
    \subfileinclude{parsing-pipeline.tex}

    \section{Contributions}
    \subfileinclude{contributions.tex}
    
    \section{Lexicalized Rule Extraction}
    \subfileinclude{extraction.tex}
    \subfileinclude{guides.tex}

    \begin{frame}<21->{Lexicalized Rule Extraction: Nonterminal Constructors}
        \resizebox{\linewidth}{!}{\subfile{figures/12-nonterminals.tex}}
    \end{frame}

    \section{Experiments}
    \begin{frame}{Experimental Setup}
%        \begin{minipage}{.5\linewidth}
            \begin{itemize}
                \item<+-> three treebanks
                \begin{itemize}
                    \item NEGRA (German)
                    \item TIGER (German)
                    \item DPTB (English)
                    \item each with training, development and test portions
                \end{itemize}
                \item<+-> three neural prediction models
                \begin{itemize}
                    \item supervised (fresh embeddings and LSTM layers)
                    \item pretrained (BERT-base, BERT-large or equivalent)
                \end{itemize}
                \item<+-> grid search for extraction and parsing parameters
                \begin{itemize}
                    \item 70 extraction and 48 parsing configurations per model in NEGRA
                    \item 20 extraction and 12 parsing configurations per model in TIGER and DPTB
                \end{itemize}
                \item<+-> final results using best configuration per prediction model and treebank
                \begin{itemize}
                    \item average parsing scores for multiple random initializations per prediction model and treebank
                \end{itemize}
            \end{itemize}
%        \end{minipage}
    \end{frame}

    % %% Intro to prediction models
    % \begin{frame}<14,15>{A Supertagging-based Parsing Pipeline}
    %     \resizebox{\linewidth}{!}{\subfile{figures/08-pipeline-overlays.tex}}
    % \end{frame}

%     \section{Neural Prediction Models}
%     \begin{frame}{Neural Prediction Models}
% %        \begin{minipage}{.5\linewidth}
%             \begin{itemize}
%                 \item<+-> pretrained transformer models \citep[semi-supervised;][]{vaswani2017attention, Devlin2019}
%                 \begin{itemize}
%                     \item used as off-the-shelf encoding
%                     \item decoding via feed-forward layers
%                     \item fine-tuning with extracted supertags + pos tags
%                     \item used in s.o.t.a. models in various tasks including parsing \citep{Cor20, FerGom22,Coa21, Sun22}
%                 \end{itemize}
%                 \item<+-> architecture without pretraining (supervised)
%                 \begin{itemize}
%                     \item fresh word + character-based embeddings
%                     \item encoding via bidrectional LSTM \citep{Hoc97} layers
%                     \item decoding via feed-forward layers
%                     \item training from ground up with extracted data
%                     \item established in supertagging and parsing \citep{vaswani2016supertagging, Cor20, StaSte20}
%                 \end{itemize}
%             \end{itemize}
% %        \end{minipage}
%     \end{frame}


%     \section{Experimental Evaluation and Results}
%     \begin{frame}{Extraction Parameters: Guide and Nonterminal Constructors (in NeGra)}
%         \subfile{tables/02-guides-nonterminals.tex}
%     \end{frame}

%     \begin{frame}{Extraction Parameters: Binarization and Markovization (in NeGra)}
%         \subfile{tables/03-binarization.tex}
%     \end{frame}

    \begin{frame}{Results: Semi-Supervised Models \citep{Rup22}}
        \defcitealias{FerGom22}{Fern{\'a}ndez-G., G{\'o}mez-R., 2022}
        \defcitealias{VilGom20}{Vilares, Gómez-R., 2020}
        \defcitealias{FerGon21a}{Fern{\'a}ndez-G., G{\'o}mez-R., 2021a}
        \defcitealias{FerGon21b}{Fern{\'a}ndez-G., G{\'o}mez-R., 2021b}
        \small\centering
        \setlength\tabcolsep{4pt} % default value: 6pt
        \resizebox{\linewidth}{!}{
            \begin{tabular}{c|lc*{3}{|ccc}}
                \toprule
                \multirow{2}{*}{Type} & \multirow{2}{*}{Model} & pretrained & \multicolumn{3}{c|}{NeGra}  & \multicolumn{3}{c|}{Tiger}  & \multicolumn{3}{c}{DPTB} \\
                &                        & embeddings &  F1   & F1-d   & sent/s & F1 & F1-d  & sent/s & F1 & F1-d & sent/s  \\\midrule
                \multirow{3}{*}{G}
                & \citealp{CraSchBod16}           & -- & 76.8  &   --   &   2 & 78.2 &   --   &  1 & 87.0 & --   & $<1$ \\
                & \citealp{Geb20}                 & -- & 81.7  &  43.5  &  -- & 77.7 &  40.7  & -- &  --  & --   & --   \\
                & \citealp{Ver16}                 & -- & --    &  --    &  -- & 79.5 & --     & -- &  --  &  --  & --   \\
                \midrule
                \multirow{3}{*}{GS}
                %        & ours                      & --        & 83.7  &  52.9  &  132 & 83.7 & 59.5   & 104 & 91.7 & 74.2 & 82        \\
                & this work                      & (bert-b) & 91.8  &  74.6  & 120 & 89.7 &  72.6  &105 & 94.4 & 82.0 & 81   \\
                & this work                      & (bert-L) & \bfseries 93.9  &  \bfseries 79.1  &  88 &  91.6 &  \bfseries 75.4  & 77 & 94.9 & 82.4 & 64          \\
                %        & \citealp{RupMoe21}        & --       & 82.7  &  49.0  &  136 & 82.5 &  55.9  & 101 & 90.1 & 72.9 & 95   \\
                & \citealp{RupMoe21}        & (bert-b) & 90.9  &  72.6  &  68 & 88.3 &  69.0  & 60 & 93.3 & 80.5 & 57   \\\midrule
                \multirow{1}{*}{C}
                %        & \citealp{Cor20}           & --       & 86.3  &  56.1  & 478 & 85.2 &  51.2  & 474& 92.9 & 64.9 & 355               \\
                & \citealp{Cor20}           & (bert-b) & 91.6  &  66.1  &  -- & 90.0 &  62.1  & -- & 94.8 & 68.9 & --   \\
%                & \citealp{StaSte20}        & --       & 83.3  &  50.7  &  15 & 83.4 &  53.5  &  9 & 90.5 & 67.7 & --   \\
                \midrule
                \multirow{1}{*}{T}
                %        & \citealp{Coa21}           & --       & 82.3  &  55.6  &  -- & 82.9 &  57.4  & -- & 91.4 & 74.4 & --   \\
                & \citealp{Coa21}           & (bert-b) & 91.7  &  73.3  &  -- & 90.2 &  72.9  & -- & 95.0 & 82.5 & --   \\\midrule
                \multirow{6}{*}{N}
                %        & \citetalias{VilGom20}     &--        & 77.1  &  36.5  & 715 &  79.2&  40.1  & 568& 89.1 & 41.8 &    611               \\
                & \citetalias{VilGom20}     & (bert-b) & 84.2  &  46.9  &  80 & 84.7 &  51.6  & 80 & 91.7 & 49.1 &  80  \\
                & \citetalias{VilGom20}     & (bert-L) & --    &  --    & --  & --   &  --    & -- & 92.8 & 53.9 &  --  \\
                & \citetalias{FerGon21a}    & (bert-b) & 90.0  & 65.9   & 275 & 88.5 & 63.0   &238 & 94.0 & 72.9 & 231  \\
                & \citetalias{FerGon21a}    & (bert-L) & 92.0  & 67.9   & 216 & 90.5 & 68.1   &207 & 95.1 & 74.1 & 193  \\
                & \citetalias{FerGon21b}    & (bert-L) & 89.1  & 67.1   & --  & 88.5 & 67.8   & -- & \bfseries 95.5 & \bfseries 82.9 & --   \\
                & \citetalias{FerGom22}     & (bert-b) & 91.0  & 76.6   & --  & 90.0 & 62.6   &--  & --   & --   &
                 --   \\
                & \citealp{Sun22}   & (bert-L)      & 93.6  & 77.0   & 185 &\bfseries 91.9 & 73.9   & 177& 95.0&75.8&161   \\
                \bottomrule
            \end{tabular}
        }
    \end{frame}

    \begin{frame}{Results: Supervised Models \citep{Rup22}}
        \defcitealias{FerGom22}{Fern{\'a}ndez-G., G{\'o}mez-R., 2022}
        \defcitealias{VilGom20}{Vilares, Gómez-R., 2020}
        \defcitealias{FerGon21a}{Fern{\'a}ndez-G., G{\'o}mez-R., 2021a}
        \defcitealias{FerGon21b}{Fern{\'a}ndez-G., G{\'o}mez-R., 2021b}
        \small\centering
        \setlength\tabcolsep{4pt} % default value: 6pt
        \resizebox{\linewidth}{!}{
            \begin{tabular}{c|lc*{3}{|ccc}}
                \toprule
                \multirow{2}{*}{Type} & \multirow{2}{*}{Model} & pretrained & \multicolumn{3}{c|}{NeGra}  & \multicolumn{3}{c|}{Tiger}  & \multicolumn{3}{c}{DPTB} \\
                &                        & embeddings &  F1   & F1-d   & sent/s & F1 & F1-d  & sent/s & F1 & F1-d & sent/s  \\\midrule
                \multirow{3}{*}{G}
                & \citealp{CraSchBod16}           & -- & 76.8  &   --   &   2 & 78.2 &   --   &  1 & 87.0 & --   & $<1$ \\
                & \citealp{Geb20}                 & -- & 81.7  &  43.5  &  -- & 77.7 &  40.7  & -- &  --  & --   & --   \\
                & \citealp{Ver16}                 & -- & --    &  --    &  -- & 79.5 & --     & -- &  --  &  --  & --   \\
                \midrule
                \multirow{2}{*}{GS}
                & this work                   & --        & 83.7  &  52.9  &  132 & 83.7 & \bfseries59.5   & 104 & 91.7 & 74.2 & 82        \\
                & \citealp{RupMoe21}        & --       & 82.7  &  49.0  &  136 & 82.5 &  55.9  & 101 & 90.1 & 72.9 & 95   \\\midrule
                \multirow{2}{*}{C}
                & \citealp{Cor20}           & --       & \bfseries86.3  & \bfseries 56.1  & 478 & \bfseries85.2 &  51.2  & 474& \bfseries92.9 & 64.9 & 355               \\
                & \citealp{StaSte20}        & --       & 83.3  &  50.7  &  15 & 83.4 &  53.5  &  9 & 90.5 & 67.7 & --   \\
                \midrule
                \multirow{1}{*}{T}
                & \citealp{Coa21}           & --       & 82.3  &  55.6  &  -- & 82.9 &  57.4  & -- & 91.4 & \bfseries74.4 & --   \\\midrule
                \multirow{1}{*}{N}
                & \citetalias{VilGom20}     &--        & 77.1  &  36.5  & 715 &  79.2&  40.1  & 568& 89.1 & 41.8 &    611               \\
                \bottomrule
            \end{tabular}
        }
    \end{frame}


    \section{Publications}
    \begin{frame}{Publications}
        \begin{itemize}
            \item \citealp*{RupDen19}, \emph{Implementation of a {C}homsky-Sch{\"u}tzenberger n-best parser for weighted multiple context-free grammars} in \emph{NAACL Proceedings}.
                \begin{itemize}
                    \item statistical parser implementation for LCFRS
                    \item includes context-free approximation, refinement and fallbacks
                \end{itemize}
            \item \citealp{MoeRup20}\emph{Lexicalization of Probabilistic Linear Context-free Rewriting Systems} in \emph{IWPT Proceedings}.
                \begin{itemize}
                    \item lexicalization scheme for probabilistic LCFRS and $k$-best parsing
                \end{itemize}
            \item \citealp{RupMoe21}, \emph{Supertagging-based Parsing with Linear Context-free Rewriting Systems} in \emph{NAACL Proceedings}.
                \begin{itemize}
                    \item supertag extraction using LCFRS based on previous paper
                    \item parsing included fallback mechanisms similar to first paper
                \end{itemize}
            \item \citealp{Rup22}, \emph{Improving the Extraction of Supertags for Constituency Parsing with Linear Context-Free Rewriting Systems} in \emph{Findings of ACL: EMNLP}.
                \begin{itemize}
                    \item modularization an generalization of extraction scheme for LCFRS supertags
                    \item evaluation of extraction parameters
                \end{itemize}
        \end{itemize}
    \end{frame}


    \section*{References}
    \begin{frame}[fragile,noframenumbering,plain,allowframebreaks]{References}
        \footnotesize
        \bibliography{references}
        \bibliographystyle{acl_natbib}
    \end{frame}
\end{document}
